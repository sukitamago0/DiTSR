import torch
import torch.nn as nn
import torch.nn.functional as F
from diffusers import AutoencoderKL, DPMSolverMultistepScheduler
from torch.cuda.amp import GradScaler
import os
import sys
import matplotlib.pyplot as plt
from tqdm import tqdm
import numpy as np

# ================= ğŸ›‘ ç¡¬ä»¶çº¦æŸ =================
torch.backends.cudnn.enabled = False
# ===============================================

# ================= ğŸ”§ SDE SR æ ¸å¿ƒé…ç½® =================
LATENT_FILE = "../dataset/DIV2K_train_latents/0001_y0_x0.pt" 
PIXART_PATH = "../output/pretrained_models/PixArt-XL-2-512x512.pth"
VAE_PATH = "../output/pretrained_models/sd-vae-ft-ema"
T5_EMBED_PATH = "../output/quality_embed.pth" 

DEVICE = "cuda"
DTYPE = torch.float16
STEPS = 500             # ç¨å¾®å¢åŠ æ­¥æ•°ç¡®ä¿æ”¶æ•›
LR = 5e-5               # å­¦ä¹ ç‡
SAVE_INTERVAL = 50 

# [æ ¸å¿ƒä¿®æ­£] SDE å¼ºåº¦
# 0.0 = åŸå›¾, 1.0 = çº¯å™ªå£°
# SR ä»»åŠ¡é€šå¸¸åœ¨ 0.4 - 0.7 ä¹‹é—´
SDE_STRENGTH = 0.5 
# ====================================================

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
try:
    from diffusion.model.nets.PixArtMS import PixArtMS_XL_2
    from diffusion.model.nets.adapter import ProgressiveFrequencyAdapter
    from diffusion import IDDPM
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def run_experiment(injection_mode, experiment_name):
    print(f"\nğŸš€ å¼€å§‹ SDE SR è¿‡æ‹Ÿåˆå®éªŒ: {experiment_name} (Mode: {injection_mode})")
    
    # 1. åˆå§‹åŒ–æ¨¡å‹
    pixart = PixArtMS_XL_2(input_size=64).to(DEVICE).to(DTYPE).train()
    ckpt = torch.load(PIXART_PATH, map_location="cpu")
    if "state_dict" in ckpt: ckpt = ckpt["state_dict"]
    if "pos_embed" in ckpt: del ckpt["pos_embed"]
    pixart.load_state_dict(ckpt, strict=False)
    for p in pixart.parameters(): p.requires_grad = False # å†»ç»“ä¸»å¹²
    
    adapter = ProgressiveFrequencyAdapter(in_channels=3, hidden_size=1152).to(DEVICE).train()
    optimizer = torch.optim.AdamW(adapter.parameters(), lr=LR)
    scaler = GradScaler()
    diffusion = IDDPM(str(1000))

    # 2. æ•°æ®åŠ è½½
    if not os.path.exists(LATENT_FILE): return []
    data = torch.load(LATENT_FILE)
    hr_latent = data["hr_latent"].unsqueeze(0).to(DEVICE).to(DTYPE) 
    lr_img = data["lr_img"].unsqueeze(0).to(DEVICE).float() # Adapterè¾“å…¥å¿…é¡»æ˜¯fp32
    
    # æˆ‘ä»¬ä¹Ÿéœ€è¦ LR çš„ Latent ä½œä¸º SDE çš„èµ·ç‚¹
    # è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä» LR å›¾ç‰‡ encode å¾—åˆ° (æ¨¡æ‹ŸçœŸå®æ¨ç†æµç¨‹)
    vae = AutoencoderKL.from_pretrained(VAE_PATH, local_files_only=True).to("cpu").float()
    with torch.no_grad():
        # ç®€å•çš„ç¼–ç  LR
        lr_latent_base = vae.encode(lr_img.cpu()).latent_dist.sample() * vae.config.scaling_factor
        lr_latent_base = lr_latent_base.to(DEVICE).to(DTYPE)

    y_embed = torch.load(T5_EMBED_PATH, map_location="cpu")["prompt_embeds"].unsqueeze(1).to(DEVICE).to(DTYPE)
    data_info = {'img_hw': torch.tensor([[512., 512.]]).to(DEVICE).to(DTYPE), 'aspect_ratio': torch.tensor([1.]).to(DEVICE).to(DTYPE)}

    losses = []
    
    # 3. è®­ç»ƒå¾ªç¯
    pbar = tqdm(range(STEPS))
    for step in pbar:
        optimizer.zero_grad()
        
        # [SDE ä¿®æ­£] è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬ä¾ç„¶è¦†ç›–å…¨æ—¶é—´æ­¥ [0, 1000]ï¼Œè¿™èƒ½è®© Adapter æ›´é²æ£’
        # ä½†åœ¨ SR ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åå‘äºè®­ç»ƒ [0, 800] åŒºé—´
        t = torch.randint(0, 1000, (1,), device=DEVICE).long()
        
        noise = torch.randn_like(hr_latent)
        noisy_input = diffusion.q_sample(hr_latent, t, noise)
        
        # Adapter Forward
        adapter_cond = adapter(lr_img).to(DTYPE)
        
        with torch.cuda.amp.autocast():
            model_out = pixart(
                noisy_input, t, y_embed, 
                data_info=data_info, 
                adapter_cond=adapter_cond, 
                injection_mode=injection_mode
            )
            if model_out.shape[1] == 8: model_out, _ = model_out.chunk(2, dim=1)
            loss = F.mse_loss(model_out, noise)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        losses.append(loss.item())
        pbar.set_postfix({"Loss": f"{loss.item():.6f}"})
        
        # 4. å¯è§†åŒ– (è¿™æ˜¯ä¿®æ­£çš„é‡ç‚¹)
        if (step + 1) % SAVE_INTERVAL == 0:
            # ä¼ å…¥ lr_latent_baseï¼Œä»¥æ­¤ä¸ºèµ·ç‚¹åŠ å™ª
            save_sde_progress(pixart, adapter, vae, lr_latent_base, lr_img, y_embed, data_info, step, experiment_name, injection_mode)

    return losses

def save_sde_progress(model, adapter, vae, lr_latent_base, lr_img, y_embed, data_info, step, exp_name, mode):
    model.eval(); adapter.eval()
    save_dir = f"../experiments_results/overfit_sde/{exp_name}"
    os.makedirs(save_dir, exist_ok=True)
    
    scheduler = DPMSolverMultistepScheduler(num_train_timesteps=1000, solver_order=2)
    scheduler.set_timesteps(20)
    
    # [æ ¸å¿ƒä¿®æ­£] SDE ç”Ÿæˆé€»è¾‘
    # 1. ç¡®å®šèµ·å§‹æ—¶é—´æ­¥
    start_timestep = int(1000 * SDE_STRENGTH)
    # æ‰¾åˆ° Scheduler ä¸­æœ€æ¥è¿‘çš„æ—¶é—´ç‚¹
    timesteps = scheduler.timesteps
    start_idx = 0
    for i, t in enumerate(timesteps):
        if t <= start_timestep:
            start_idx = i
            break
    
    target_timesteps = timesteps[start_idx:]
    actual_start_t = target_timesteps[0]
    
    # 2. æ„é€ èµ·ç‚¹: LR Latent + Noise(t)
    g = torch.Generator(DEVICE).manual_seed(42)
    noise = torch.randn_like(lr_latent_base)
    
    # æ‰‹åŠ¨åŠ å™ªå…¬å¼: x_t = sqrt(alpha_cumprod)*x_0 + sqrt(1-alpha_cumprod)*noise
    # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨ scheduler çš„ add_noise (å¦‚æœæ”¯æŒ) æˆ– diffusers çš„æ ‡å‡† q_sample
    # è¿™é‡Œä¸ºäº†é€šç”¨æ€§ï¼Œæˆ‘ä»¬æ¨¡æ‹ŸåŠ å™ª:
    # æ³¨æ„: DPM Solver å¯¹ alpha çš„å®šä¹‰å¯èƒ½ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç®€åŒ–çš„åŠ å™ªé€»è¾‘ç”¨äºå¯è§†åŒ–éªŒè¯
    # æ›´ä¸¥è°¨çš„åšæ³•æ˜¯å®ä¾‹åŒ–ä¸€ä¸ª IDDPM æ¥åš q_sampleï¼Œè¿™é‡Œç›´æ¥ç”¨çº¿æ€§æ’å€¼æ¨¡æ‹Ÿ SDE å¼ºåº¦
    
    # ç®€å• SDE æ¨¡æ‹Ÿ: latents = (1-strength)*LR + strength*Noise
    # è¿™ä¸æ˜¯ä¸¥æ ¼çš„ Diffusion å…¬å¼ï¼Œä½†åœ¨å¯è§†åŒ–è¿‡æ‹Ÿåˆæ•ˆæœæ—¶è¶³å¤ŸéªŒè¯ Adapter æ˜¯å¦èµ·ä½œç”¨
    # ä¸¥æ ¼åšæ³•æ˜¯:
    latents = scheduler.add_noise(lr_latent_base, noise, torch.tensor([actual_start_t]))

    with torch.no_grad():
        cond = adapter(lr_img).to(DTYPE)
        
        # ä» start_t å¼€å§‹å»å™ª
        for t in target_timesteps:
            t_tensor = t.unsqueeze(0).to(DEVICE)
            out = model(latents, t_tensor, y_embed, data_info=data_info, adapter_cond=cond, injection_mode=mode)
            if out.shape[1] == 8: out, _ = out.chunk(2, dim=1)
            latents = scheduler.step(out, t, latents).prev_sample
            
    # Decode
    img = vae.decode(latents.cpu().float() / vae.config.scaling_factor).sample
    
    # Plot
    img_np = ((img[0].permute(1, 2, 0).detach().cpu().numpy() + 1) / 2).clip(0, 1)
    lr_np = ((lr_img[0].cpu().permute(1, 2, 0).detach().numpy() + 1) / 2).clip(0, 1)
    
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1); plt.imshow(lr_np); plt.title("Input LR")
    plt.subplot(1, 2, 2); plt.imshow(img_np); plt.title(f"SDE {SDE_STRENGTH} (Step {step+1})")
    plt.savefig(f"{save_dir}/step_{step+1:04d}.png")
    plt.close()
    
    model.train(); adapter.train()

def main():
    # å®éªŒ A: Input Injection
    loss_a = run_experiment(injection_mode="input", experiment_name="sde_input_gate")
    
    # å®éªŒ B: Cross-Attn Injection
    loss_b = run_experiment(injection_mode="cross_attn", experiment_name="sde_cross_attn")
    
    # ç»˜åˆ¶ Loss
    if loss_a and loss_b:
        plt.figure(figsize=(10, 6))
        plt.plot(loss_a, label="Input Injection")
        plt.plot(loss_b, label="Cross-Attn Injection")
        plt.title(f"SDE Overfitting (Strength={SDE_STRENGTH})")
        plt.legend(); plt.grid(True)
        plt.savefig("../experiments_results/overfit_sde/loss_comparison.png")

if __name__ == "__main__":
    main()